{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRE-PINN Training on Lightning AI GPU\n",
    "\n",
    "This notebook is configured to run on Lightning AI with GPU support.\n",
    "\n",
    "## Setup Instructions:\n",
    "1. Upload the entire MRE-PINN folder to Lightning AI Studios\n",
    "2. Select a GPU runtime (e.g., T4, A10G)\n",
    "3. The MRE-PINN conda environment should have all dependencies installed\n",
    "4. The notebook will automatically use GPU if available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment\n",
    "\n",
    "# Note: Make sure you've uploaded the entire MRE-PINN repository folder to Lightning AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup environment and imports\n",
    "import sys\n",
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Navigate to parent directory to access mre_pinn module\n",
    "notebook_dir = pathlib.Path.cwd()\n",
    "repo_root = notebook_dir.parent if notebook_dir.name == 'lightning-ai-training' else notebook_dir\n",
    "sys.path.insert(0, str(repo_root))\n",
    "\n",
    "# Configure DeepXDE backend\n",
    "os.environ['DDEBACKEND'] = 'pytorch'\n",
    "import deepxde\n",
    "\n",
    "# Import MRE-PINN\n",
    "import mre_pinn\n",
    "\n",
    "# Check GPU availability\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Available GPU memory: {torch.cuda.get_device_properties(0).total_memory / 2**30:.2f} GiB\")\n",
    "else:\n",
    "    print(\"Warning: No GPU detected. Training will be slow on CPU.\")\n",
    "\n",
    "print(f\"\\nRepository root: {repo_root}\")\n",
    "print(f\"MRE-PINN module loaded from: {mre_pinn.__file__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Preprocess Data\n",
    "\n",
    "Download the BIOQIC simulation dataset and convert it to xarray format.\n",
    "\n",
    "Note: The download will automatically skip if the data already exists (thanks to the improved download check!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create data directories relative to repo root\n",
    "data_dir = repo_root / 'data' / 'BIOQIC'\n",
    "download_dir = data_dir / 'downloads'\n",
    "processed_dir = data_dir / 'fem_box'\n",
    "\n",
    "download_dir.mkdir(parents=True, exist_ok=True)\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Download directory: {download_dir}\")\n",
    "print(f\"Processed directory: {processed_dir}\")\n",
    "\n",
    "# Download and process data\n",
    "bioqic = mre_pinn.data.BIOQICFEMBox(str(download_dir))\n",
    "bioqic.download()  # Will skip if already exists\n",
    "bioqic.load_mat()\n",
    "bioqic.preprocess()\n",
    "dataset = bioqic.to_dataset()\n",
    "dataset.save_xarrays(str(processed_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directories\n",
    "data_dir = pathlib.Path('data/BIOQIC')\n",
    "download_dir = data_dir / 'downloads'\n",
    "processed_dir = data_dir / 'fem_box'\n",
    "\n",
    "download_dir.mkdir(parents=True, exist_ok=True)\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download and process data\n",
    "bioqic = mre_pinn.data.BIOQICFEMBox(str(download_dir))\n",
    "bioqic.download()\n",
    "bioqic.load_mat()\n",
    "bioqic.preprocess()\n",
    "dataset = bioqic.to_dataset()\n",
    "dataset.save_xarrays(str(processed_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example data\n",
    "frequency = 90  # Hz\n",
    "example = mre_pinn.data.MREExample.load_xarrays(str(processed_dir), frequency)\n",
    "\n",
    "# Display metadata and statistics\n",
    "print(\"\\nMetadata:\")\n",
    "print(example.metadata)\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(example.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize wave field (static plot for Lightning AI)\n",
    "example.view('wave', ax_height=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Baseline Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate AHI baseline\n",
    "mre_pinn.baseline.eval_ahi_baseline(example, frequency=frequency)\n",
    "example.view('mre', 'direct', ax_height=3, polar=True, vmax=20e3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure PINN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct PDE\n",
    "pde = mre_pinn.pde.WaveEquation.from_name('hetero', omega=frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PINN architecture\n",
    "pinn = mre_pinn.model.MREPINN(\n",
    "    example,\n",
    "    omega=frequency,\n",
    "    n_layers=5,\n",
    "    n_hidden=128,\n",
    "    activ_fn='ss',  # sin activation\n",
    "    polar_input=False\n",
    ")\n",
    "print(pinn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model with GPU Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure training model with GPU device\n",
    "model = mre_pinn.training.MREPINNModel(\n",
    "    example, pinn, pde,\n",
    "    loss_weights=[1, 0, 0, 1e-8],\n",
    "    pde_warmup_iters=1000,\n",
    "    pde_step_iters=500,\n",
    "    pde_step_factor=10,\n",
    "    pde_init_weight=1e-10,\n",
    "    n_points=1024,\n",
    "    device=device  # Automatically use GPU if available\n",
    ")\n",
    "model.compile(optimizer='adam', lr=1e-4, loss=mre_pinn.training.losses.msae_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark model performance\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True  # Enable cudnn benchmarking for better GPU performance\n",
    "model.benchmark(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Test Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test evaluator for periodic evaluation\n",
    "test_eval = mre_pinn.testing.TestEvaluator(\n",
    "    test_every=100,\n",
    "    save_every=1000,\n",
    "    save_prefix='LIGHTNING_AI',\n",
    "    interact=False  # Disable interactive mode for Lightning AI\n",
    ")\n",
    "test_eval.model = model\n",
    "test_eval.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model on GPU\n",
    "\n",
    "This will train the model for 100,000 iterations using GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Reset GPU memory stats if available\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Train the model\n",
    "print(f\"Starting training on {device}...\")\n",
    "model.train(10000, display_every=100, callbacks=[test_eval])\n",
    "\n",
    "# Display GPU memory usage\n",
    "if torch.cuda.is_available():\n",
    "    peak_memory = torch.cuda.max_memory_allocated() / 2**30\n",
    "    print(f\"\\nPeak GPU memory: {peak_memory:.2f} GiB\")\n",
    "    print(f\"GPU utilization was efficient!\")\n",
    "else:\n",
    "    print(\"\\nWarning: Training completed on CPU (no GPU detected)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation\n",
    "test_eval.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display metrics\n",
    "print(\"Training Metrics:\")\n",
    "print(test_eval.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "checkpoint_path = pathlib.Path('checkpoints')\n",
    "checkpoint_path.mkdir(exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.pinn.state_dict(),\n",
    "    'optimizer_state_dict': model.optimizer.state_dict(),\n",
    "    'frequency': frequency,\n",
    "    'device': device,\n",
    "}, checkpoint_path / 'mre_pinn_lightning_ai.pth')\n",
    "\n",
    "print(f\"Model checkpoint saved to: {checkpoint_path / 'mre_pinn_lightning_ai.pth'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Results\n",
    "\n",
    "Download the trained model and results back to your local machine from Lightning AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a zip file of all results\n",
    "!zip -r lightning_ai_results.zip checkpoints/ LIGHTNING_AI_*.png LIGHTNING_AI_*.pkl\n",
    "print(\"Results packaged. Download 'lightning_ai_results.zip' from Lightning AI file browser.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MRE-PINN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
